{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"densenet201_augment_ranger_cosineanneal_TTA_Oversampling_Mar27-Pytorch.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"175cbcWgGX2y5cTWgMLJVG9gcUQ6q1MEP","authorship_tag":"ABX9TyP+byrmv930qkBXbhI6Sch7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0aa30a41c8df4886905debcc47adc5a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_553eb24fedfe41a89918815f2365c702","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5b595df6e4ae49e2b8d0fd07d2e1846e","IPY_MODEL_3e8422fafde34923abeb9b3e759e9d7a"]}},"553eb24fedfe41a89918815f2365c702":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b595df6e4ae49e2b8d0fd07d2e1846e":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_df9cb837f71c407a81e7b5e62070b07d","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"danger","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_706a8ac5658644d5a6af8ca87b249633"}},"3e8422fafde34923abeb9b3e759e9d7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d30eaecf4d114857abc181a998410259","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/? [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b336a070927f40009fd02fbc08f58ab2"}},"df9cb837f71c407a81e7b5e62070b07d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"706a8ac5658644d5a6af8ca87b249633":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d30eaecf4d114857abc181a998410259":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b336a070927f40009fd02fbc08f58ab2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"-U8Mj_p31Jmf","colab_type":"text"},"source":["# Setup\n"]},{"cell_type":"code","metadata":{"id":"DMm4Hyf4251w","colab_type":"code","outputId":"ccfe466d-00a6-4613-bf13-15a29dc41ffc","executionInfo":{"status":"ok","timestamp":1585296380530,"user_tz":-330,"elapsed":21971,"user":{"displayName":"rohan rajpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4wl0nRpJmgIyKhLt6GrrkDZY65nYNva0sChZfsmw=s64","userId":"09487063296749812889"}},"colab":{"base_uri":"https://localhost:8080/","height":336}},"source":["PROJECT_PATH = \"/content/drive/My Drive/Deep_Learning_Assignments/Project/\"\n","%cd \"{PROJECT_PATH}\"\n","!pip install livelossplot>/tmp/xxy\n","!pip install timm>/tmp/xxy\n","!pip install neptune-client>/tmp/xxy\n","!pip install ttach > /tmp/xxy\n","# !git clone https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\n","%cd Ranger-Deep-Learning-Optimizer\n","!pip install -e .\n","!pip install geffnet\n","%env NEPTUNE_API_TOKEN=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiM2UwMDkxZmItNDhlMi00MjEzLTkxMTAtYzBiOWQxNzk2MjUyIn0=\"\n","%env NEPTUNE_PROJECT_NAME=rohanrajpal/DLproject"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Deep_Learning_Assignments/Project\n","/content/drive/My Drive/Deep_Learning_Assignments/Project/Ranger-Deep-Learning-Optimizer\n","Obtaining file:///content/drive/My%20Drive/Deep_Learning_Assignments/Project/Ranger-Deep-Learning-Optimizer\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from ranger==0.0.1) (1.4.0)\n","Installing collected packages: ranger\n","  Found existing installation: ranger 0.0.1\n","    Can't uninstall 'ranger'. No files were found to uninstall.\n","  Running setup.py develop for ranger\n","Successfully installed ranger\n","Requirement already satisfied: geffnet in /usr/local/lib/python3.6/dist-packages (0.9.8)\n","Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from geffnet) (1.4.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from geffnet) (0.5.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->geffnet) (7.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->geffnet) (1.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->geffnet) (1.18.2)\n","env: NEPTUNE_API_TOKEN=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiM2UwMDkxZmItNDhlMi00MjEzLTkxMTAtYzBiOWQxNzk2MjUyIn0=\"\n","env: NEPTUNE_PROJECT_NAME=rohanrajpal/DLproject\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jrb8XVYyLW7r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":316},"outputId":"230fcb2f-b228-4c0a-94e9-e29027464fd2","executionInfo":{"status":"ok","timestamp":1585296382925,"user_tz":-330,"elapsed":24349,"user":{"displayName":"rohan rajpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4wl0nRpJmgIyKhLt6GrrkDZY65nYNva0sChZfsmw=s64","userId":"09487063296749812889"}}},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Fri Mar 27 08:06:21 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P8     8W /  75W |      0MiB /  7611MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N794L8XfUT12","colab_type":"text"},"source":["# Imports\n"]},{"cell_type":"code","metadata":{"id":"vWVIGK2G3lY-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"62f00827-96a0-45e0-f2f9-dd6c48975c37","executionInfo":{"status":"ok","timestamp":1585296385246,"user_tz":-330,"elapsed":26656,"user":{"displayName":"rohan rajpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4wl0nRpJmgIyKhLt6GrrkDZY65nYNva0sChZfsmw=s64","userId":"09487063296749812889"}}},"source":["# %reload_ext plotcm\n","# https://github.com/rwightman/gen-efficientnet-pytorch\n","from ranger import Ranger  # this is from ranger.py\n","%cd ..\n","import torch\n","import torchvision\n","from torchvision.models import resnet18, densenet201, densenet121\n","from torchvision.transforms import transforms as T\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","import pandas as pd\n","import torch.nn as nn\n","from tqdm.auto import tqdm as tq\n","import torch.optim as optim\n","\n","from plotcm import plot_confusion_matrix\n","from sklearn.metrics import confusion_matrix\n","import geffnet\n","\n","import random\n","import math\n","import os\n","from time import sleep\n","\n","from livelossplot import PlotLosses\n","from livelossplot.outputs import NeptuneLogger\n","\n","import numpy as np\n","import pandas as pd\n","import neptune\n","from timm import create_model\n","from sklearn.model_selection import StratifiedKFold\n","\n","if torch.cuda.is_available():\n","  device=torch.device('cuda:0')\n","else:\n","  device=torch.device('cpu')\n","\n","neptune.init('rohanrajpal/DLproject')\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Deep_Learning_Assignments/Project\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Project(rohanrajpal/DLProject)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"ugkzqa2lK0sK","colab_type":"text"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"id":"nVr2BMqFK2pU","colab_type":"code","colab":{}},"source":["class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n","    \"\"\"Custom dataset that includes image file paths. Extends\n","    torchvision.datasets.ImageFolder\n","    \"\"\"\n","\n","    # override the __getitem__ method. this is the method that dataloader calls\n","    def __getitem__(self, index):\n","        # this is what ImageFolder normally returns \n","        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n","        # the image file path\n","        path = self.imgs[index][0].split('/')[-1][:-4]\n","        # make a new tuple that includes original and the path\n","        tuple_with_path = (original_tuple + (path,))\n","        return tuple_with_path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJNr6ROlhXLI","colab_type":"code","colab":{}},"source":["class RandomErasing(object):\n","    '''\n","    Class that performs Random Erasing in Random Erasing Data Augmentation by Zhong et al. \n","    -------------------------------------------------------------------------------------\n","    probability: The probability that the operation will be performed.\n","    sl: min erasing area\n","    sh: max erasing area\n","    r1: min aspect ratio\n","    mean: erasing value\n","    -------------------------------------------------------------------------------------\n","    '''\n","    def __init__(self, probability = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n","        self.probability = probability\n","        self.mean = mean\n","        self.sl = sl\n","        self.sh = sh\n","        self.r1 = r1\n","       \n","    def __call__(self, img):\n","\n","        if random.uniform(0, 1) > self.probability:\n","            return img\n","\n","        for attempt in range(100):\n","            area = img.size()[1] * img.size()[2]\n","       \n","            target_area = random.uniform(self.sl, self.sh) * area\n","            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n","\n","            h = int(round(math.sqrt(target_area * aspect_ratio)))\n","            w = int(round(math.sqrt(target_area / aspect_ratio)))\n","\n","            if w < img.size()[2] and h < img.size()[1]:\n","                x1 = random.randint(0, img.size()[1] - h)\n","                y1 = random.randint(0, img.size()[2] - w)\n","                if img.size()[0] == 3:\n","                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n","                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n","                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n","                else:\n","                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n","                return img\n","\n","        return img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E1Lpm1cbpnFP","colab_type":"code","colab":{}},"source":["class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n","    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n","    Arguments:\n","        indices (list, optional): a list of indices\n","        num_samples (int, optional): number of samples to draw\n","        callback_get_label func: a callback-like function which takes two arguments - dataset and index\n","    \"\"\"\n","\n","    def __init__(self, dataset, indices=None, num_samples=None, callback_get_label=None):\n","                \n","        # if indices is not provided, \n","        # all elements in the dataset will be considered\n","        self.indices = list(range(len(dataset))) \\\n","            if indices is None else indices\n","\n","        # define custom callback\n","        self.callback_get_label = callback_get_label\n","\n","        # if num_samples is not provided, \n","        # draw `len(indices)` samples in each iteration\n","        self.num_samples = len(self.indices) \\\n","            if num_samples is None else num_samples\n","            \n","        # distribution of classes in the dataset \n","        label_to_count = {}\n","        for idx in self.indices:\n","            label = self._get_label(dataset, idx)\n","            if label in label_to_count:\n","                label_to_count[label] += 1\n","            else:\n","                label_to_count[label] = 1\n","                \n","        # weight for each sample\n","        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n","                   for idx in self.indices]\n","        self.weights = torch.DoubleTensor(weights)\n","\n","    def _get_label(self, dataset, idx):\n","        if isinstance(dataset, torchvision.datasets.MNIST):\n","            return dataset.train_labels[idx].item()\n","        elif isinstance(dataset, torchvision.datasets.ImageFolder):\n","            return dataset.imgs[idx][1]\n","        elif self.callback_get_label:\n","            return self.callback_get_label(dataset, idx)\n","        else:\n","            raise NotImplementedError\n","                \n","    def __iter__(self):\n","        return (self.indices[i] for i in torch.multinomial(\n","            self.weights, self.num_samples, replacement=True))\n","\n","    def __len__(self):\n","        return self.num_samples"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0wdvzWBeDLA_","colab_type":"text"},"source":["# Train valid test dataset"]},{"cell_type":"code","metadata":{"id":"ZMpy4EZA3fE5","colab_type":"code","colab":{}},"source":["img_size = 224\n","\n","def get_train_valid_dataset(data_dir,\n","                           batch_size,\n","                           augment,\n","                           random_seed,\n","                           valid_size=0.1,\n","                           shuffle=True,\n","                           show_sample=False,\n","                           num_workers=4,\n","                           pin_memory=False,\n","                           split_no=1):\n","    \"\"\"\n","    Utility function for loading and returning train and valid\n","    multi-process iterators over the CIFAR-10 dataset. A sample\n","    9x9 grid of the images can be optionally displayed.\n","    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n","    Params\n","    ------\n","    - data_dir: path directory to the dataset.\n","    - batch_size: how many samples per batch to load.\n","    - augment: whether to apply the data augmentation scheme\n","      mentioned in the paper. Only applied on the train split.\n","    - random_seed: fix seed for reproducibility.\n","    - valid_size: percentage split of the training set used for\n","      the validation set. Should be a float in the range [0, 1].\n","    - shuffle: whether to shuffle the train/validation indices.\n","    - show_sample: plot 9x9 sample grid of the dataset.\n","    - num_workers: number of subprocesses to use when loading the dataset.\n","    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n","      True if using GPU.\n","    Returns\n","    -------\n","    - train_loader: training set iterator.\n","    - valid_loader: validation set iterator.\n","    \"\"\"\n","    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n","    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n","\n","    normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","    valid_transform = T.Compose([\n","            T.Resize([img_size, img_size]),\n","            T.ToTensor(),\n","            normalize,\n","    ])\n","    if augment:\n","        train_transform = T.Compose([\n","          T.RandomApply([T.RandomAffine(45, shear=15)], 0.8),\n","          T.RandomResizedCrop(img_size, scale=(0.6, 1.0), ratio=(3/5, 5/3)),\n","          T.RandomHorizontalFlip(),\n","          T.RandomVerticalFlip(),\n","          T.ToTensor(),\n","          T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","          RandomErasing(probability=0.3, sh=0.3)])\n","    else:\n","        train_transform = T.Compose([\n","            T.Resize([img_size, img_size]),\n","            T.ToTensor(),\n","            normalize,\n","        ])\n","    train_dataset = torchvision.datasets.ImageFolder(\n","        root=data_dir,\n","        transform=train_transform\n","    )\n","    # print(train_dataset.class_to_idx)\n","    valid_dataset = torchvision.datasets.ImageFolder(\n","        root=data_dir,\n","        transform=valid_transform\n","    )\n","\n","    return (train_dataset, valid_dataset)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MutZrs2z47hE","colab_type":"text"},"source":["## Test loader"]},{"cell_type":"code","metadata":{"id":"8dHLkHFI44qC","colab_type":"code","colab":{}},"source":["def get_test_loader(data_dir,\n","                    batch_size,\n","                    shuffle=True,\n","                    num_workers=4,\n","                    pin_memory=False):\n","    \"\"\"\n","    Utility function for loading and returning a multi-process\n","    test iterator over the CIFAR-10 dataset.\n","    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n","    Params\n","    ------\n","    - data_dir: path directory to the dataset.\n","    - batch_size: how many samples per batch to load.\n","    - shuffle: whether to shuffle the dataset after every epoch.\n","    - num_workers: number of subprocesses to use when loading the dataset.\n","    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n","      True if using GPU.\n","    Returns\n","    -------\n","    - data_loader: test set iterator.\n","    \"\"\"\n","    normalize = T.Normalize(\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225],\n","    )\n","    # define transform\n","    transform = T.Compose([\n","        T.Resize([img_size, img_size]),\n","        T.ToTensor(),\n","        normalize,\n","    ])\n","\n","    dataset = ImageFolderWithPaths(\n","        root=data_dir,\n","        transform=transform\n","    )\n","\n","    data_loader = torch.utils.data.DataLoader(\n","        dataset, batch_size=batch_size, shuffle=shuffle,\n","        num_workers=num_workers, pin_memory=pin_memory,\n","    )\n","\n","    return data_loader"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_eScv8yoDODS","colab_type":"text"},"source":["# Dataloader"]},{"cell_type":"code","metadata":{"id":"Waow0Xwe3x2H","colab_type":"code","colab":{}},"source":["# train_loader, valid_loader = get_train_valid_loader(PROJECT_PATH + \"data/train/\",batch_size=32,augment=True,\n","#                                                     random_seed=42,valid_size=0.2,shuffle=True,show_sample=False,\n","#                                                     num_workers=4,pin_memory=True,split_no=2)\n","test_loader = get_test_loader(PROJECT_PATH + \"data/test/\",32,False,4,True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1nrbi8Gibsl6","colab_type":"text"},"source":["# Train"]},{"cell_type":"code","metadata":{"id":"pKgPYrD2Jk-7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"47578a8c-dd7c-41cf-e34f-cd6844ae339c","executionInfo":{"status":"ok","timestamp":1585296385250,"user_tz":-330,"elapsed":26578,"user":{"displayName":"rohan rajpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4wl0nRpJmgIyKhLt6GrrkDZY65nYNva0sChZfsmw=s64","userId":"09487063296749812889"}}},"source":["%time\n","# %load_ext autoreload\n","\n","def eval(valid_loader, model, loss_compute, plot_matrix):\n","  model.eval()\n","\n","  whole_loss = []\n","  whole_output = []\n","  whole_label = []\n","\n","  with torch.no_grad():\n","    for batch_idx, (data,label) in enumerate(tq(valid_loader)):\n","      data, label = data.to(device, dtype=torch.float32), label.to(device)\n","      \n","      output = model(data)\n","      loss = loss_compute(output,label)\n","      whole_loss.append(loss.item())\n","      if plot_matrix:\n","        whole_output.append(output.cpu().detach().numpy())\n","        whole_label.append(label.cpu().detach().numpy())\n","\n","  if plot_matrix:\n","    whole_label = np.concatenate(whole_label)\n","    whole_output = np.concatenate(whole_output)\n","    whole_output = whole_output.argmax(axis=1)\n","\n","  if plot_matrix == True:\n","    plot_confusion_matrix(confusion_matrix(whole_label,whole_output),[str(x) for x in range(3)])\n","\n","  return np.mean(whole_loss)\n","\n","def train(epochs,data_loader,valid_loader,model,lr,best_wt_name):\n","  plotlosses = PlotLosses(groups={'log-loss': ['loss', 'val_loss']})\n","  optimizer = optim.AdamW(model.parameters(),lr=lr)\n","  loss_compute = nn.CrossEntropyLoss()\n","  lr_scheduler = None\n","  best_model = {'loss':100, 'path':PROJECT_PATH + \"data/models/pytorchnb/\" + best_wt_name}\n","\n","  for i in tq(range(1,epochs+1)):\n","    model.train()\n","\n","    whole_loss = []\n","\n","    if i+1 == epochs//2 and lr_scheduler == None:\n","      print(\"Scheduler started\")\n","      lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs/2, eta_min = 1e-7)\n","    \n","    for batch_idx, (data,label) in enumerate(tq(data_loader)):\n","      \n","      data, label = data.to(device, dtype=torch.float32), label.to(device)\n","      output = model(data)\n","      # print(output.shape)\n","      loss = loss_compute(output,label)\n","      \n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      whole_loss.append(loss.item())\n","      \n","    \n","    train_loss = np.mean(whole_loss)\n","\n","    valid_loss = eval(valid_loader,model,loss_compute,False)\n","\n","    if best_model['loss'] > valid_loss:\n","      best_model['loss'] = valid_loss\n","      torch.save(model.state_dict(),best_model['path'])\n","\n","    plotlosses.update({\n","        'loss': train_loss,\n","        'val_loss': valid_loss,\n","        # 'val_accuracy' : accuracy\n","    })\n","    plotlosses.send()\n","    neptune.log_metric('val_loss', valid_loss)\n","    neptune.log_metric('train_loss', train_loss)\n","\n","    if lr_scheduler != None:\n","      lr_scheduler.step()\n","\n","  # Confusion matrix of the best model\n","  model.load_state_dict(torch.load(best_model['path']))\n","  loss = eval(valid_loader,model,loss_compute,True)\n","  print(\"Best valid loss\",loss)\n","  return model\n","  \n","\n","def trainCNN(epochs,data_loader,valid_loader,model_name,pretrained,best_wt_name,lr,load_trained=False):\n","  # https://github.com/rwightman/pytorch-image-models\n","  # model = create_model(model_name, pretrained=True)\n","  # model = geffnet.create_model(model_name, pretrained=True,act_layer='mish')\n","  model = densenet201(pretrained=True)\n","  in_features = model.classifier.in_features\n","  model.classifier = nn.Linear(in_features=in_features, out_features=3, bias=True)\n","  model = model.to(device)\n","  # print(model)\n","  if load_trained:\n","    model.load_state_dict(torch.load(PROJECT_PATH+\"data/models/pytorchnb/\" + best_wt_name))\n","    return model\n","  # print(model)\n","  return train(epochs,data_loader,valid_loader,model,lr,best_wt_name)\n","\n","\n","# model_name = 'tf_efficientnet_b6'\n","# save_name = model_name+'_TTA_Oversampling_Adam_Pytorch'\n","# PARAMS = {'learning_rate' : 1e-4,\n","#           'n_epochs' : 20,\n","#           'optimizer' : 'Adam',\n","#           'model' : model_name\n","#           }\n","# neptune.create_experiment(name='pytorch-'+model_name+'-Adam', params=PARAMS)\n","# model = trainCNN(PARAMS['n_epochs'],train_loader,valid_loader,model_name,True,\n","#                  save_name,PARAMS['learning_rate'],False)\n","\n","# model"],"execution_count":10,"outputs":[{"output_type":"stream","text":["CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n","Wall time: 4.77 µs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l9tZdmmiYV2b","colab_type":"text"},"source":["# Predict"]},{"cell_type":"code","metadata":{"id":"uRQx98QNXP-4","colab_type":"code","colab":{}},"source":["import torch.nn.functional as F\n","import ttach as tta\n","\n","# tta_model = tta.ClassificationTTAWrapper(model, tta.aliases.flip_transform(), merge_mode='mean')\n","\n","def predict(valid_loader, model, do_tta=False):\n","  if do_tta:\n","    model = tta.ClassificationTTAWrapper(model, tta.aliases.flip_transform(), merge_mode='mean')\n","  model.eval()\n","\n","  # whole_loss = []\n","  whole_output = []\n","  whole_img_paths = []\n","\n","  loss_compute = nn.CrossEntropyLoss()\n","\n","  with torch.no_grad():\n","    for batch_idx, (data,label, paths) in enumerate(tq(valid_loader)):\n","      data, label = data.to(device, dtype=torch.float32), label.to(device)\n","      output = model(data)\n","      whole_output.append(output.cpu().detach().numpy())\n","      whole_img_paths += paths\n","\n","  whole_output = np.concatenate(whole_output)\n","  probs = F.softmax(torch.from_numpy(whole_output), dim=1)\n","\n","  return whole_img_paths, probs\n","\n","# preds_path,preds_prob = predict(test_loader, model, True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pxbkCQW8YcPZ","colab_type":"text"},"source":["# Make Submission"]},{"cell_type":"code","metadata":{"id":"X_hNpVWdYLet","colab_type":"code","colab":{}},"source":["def make_submission(preds_prob,preds_path,save_name):\n","  test_path = PROJECT_PATH+\"data/test/test\"\n","  # test_path = PROJECT_PATH + \"/other-data/test/\"\n","  # print(model.data.classes)\n","  # submission = pd.DataFrame({'ID': [s.split('.')[0] for s in os.listdir(test_path)  if s.split('.')[1] != 'jfif']})\n","  submission = pd.DataFrame({'ID': preds_path})\n","  # submission\n","  for i, c in enumerate(['healthy_wheat', 'leaf_rust', 'stem_rust']):\n","    # print(preds_test[:,i].shape)\n","    # print(c)\n","    submission[c] = preds_prob[:,i]\n","  submission = submission[['ID', 'leaf_rust', 'stem_rust', 'healthy_wheat']] # Get same order as sample sub\n","  print(submission)\n","  submission.to_csv(PROJECT_PATH+'submissions/'+save_name+'.csv', index = False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yq-Uel6F8X0h","colab_type":"text"},"source":["# Cross validation"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"a179c9a5-bcae-4d59-aefb-6e5a853c937d","id":"H2ud38MdKTZ4","colab":{"base_uri":"https://localhost:8080/","height":287,"referenced_widgets":["0aa30a41c8df4886905debcc47adc5a6","553eb24fedfe41a89918815f2365c702","5b595df6e4ae49e2b8d0fd07d2e1846e","3e8422fafde34923abeb9b3e759e9d7a","df9cb837f71c407a81e7b5e62070b07d","706a8ac5658644d5a6af8ca87b249633","d30eaecf4d114857abc181a998410259","b336a070927f40009fd02fbc08f58ab2"]},"executionInfo":{"status":"error","timestamp":1585298818603,"user_tz":-330,"elapsed":1263,"user":{"displayName":"rohan rajpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4wl0nRpJmgIyKhLt6GrrkDZY65nYNva0sChZfsmw=s64","userId":"09487063296749812889"}}},"source":["num_splits = 5\n","all_probs = torch.zeros(610, 3, dtype=torch.float32)\n","# for i in range(2,2+1):\n","train_dataset, valid_dataset = get_train_valid_dataset(PROJECT_PATH + \"data/train/\",batch_size=32,augment=True,\n","                                                    random_seed=42,valid_size=0.2,shuffle=True,show_sample=False,\n","                                                    num_workers=4,pin_memory=True,split_no=1)\n","skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n","# https://discuss.pytorch.org/t/how-can-i-use-sklearn-kfold-with-imagefolder/36577\n","# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\n","batch_size=32\n","num_workers=4\n","pin_memory=True\n","for fold_num, (train_index, test_index) in enumerate(tq(skf.split(train_dataset, train_dataset.targets))):\n","  # train_subset = torch.utils.data.Subset(train_dataset,train_index)\n","  # valid_subset = torch.utils.data.Subset(valid_dataset,test_index)\n","  if fold_num != 4:\n","    continue\n","\n","  train_sampler = ImbalancedDatasetSampler(train_dataset,train_index)\n","  valid_sampler = ImbalancedDatasetSampler(valid_dataset,test_index)\n","\n","  train_loader = torch.utils.data.DataLoader(\n","      train_dataset, batch_size=batch_size, sampler=train_sampler,\n","      num_workers=num_workers, pin_memory=pin_memory\n","  )\n","  valid_loader = torch.utils.data.DataLoader(\n","      valid_dataset, batch_size=batch_size, sampler=valid_sampler,\n","      num_workers=num_workers, pin_memory=pin_memory\n","  )\n","  \n","  model_name = 'densenet201'\n","  optim_name = 'AdamW'\n","  lr =1e-5\n","  PARAMS = {'learning_rate' : lr,\n","            'n_epochs' : 20,\n","            'optimizer' : optim_name,\n","            'model' : model_name,\n","            'fold' : fold_num,\n","            'save_name': model_name+'_TTA_'+optim_name+'_fold_'+str(img_size)+'_'+string(lr)+'_'+str(fold_num)\n","            }\n","  neptune.create_experiment(name='pytorch-'+model_name+'-Adam', params=PARAMS)\n","  print(\"Started train for fold\",fold_num)\n","  model = trainCNN(PARAMS['n_epochs'],train_loader,valid_loader,model_name,True,\n","                  PARAMS['save_name'],PARAMS['learning_rate'],False)\n","  preds_path,preds_prob = predict(test_loader, model,True)\n","  \n","  make_submission(preds_prob,preds_path,PARAMS['save_name'])\n","\n","  all_probs+= preds_prob\n","\n","# Change optimizer to adam maybe\n","# Or change the scheduler to cosine annealing\n","\n","# TODO: Generate a CV score\n","# all_probs /= num_splits\n","# preds_path,preds_prob = preds_path, all_probs\n","# make_submission(preds_prob,preds_path,model_name+\"_5-fold_cv_pytorch\")"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0aa30a41c8df4886905debcc47adc5a6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-38782c8909de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;34m'model'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;34m'fold'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfold_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;34m'save_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_TTA_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moptim_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_fold_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             }\n\u001b[1;32m     41\u001b[0m   \u001b[0mneptune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pytorch-'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPARAMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'img_size' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"C_MmBOSoAuQq","colab_type":"text"},"source":["# References\n","\n","- [k fold pytorch](https://discuss.pytorch.org/t/how-can-i-use-sklearn-kfold-with-imagefolder/36577)"]}]}